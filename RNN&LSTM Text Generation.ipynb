{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from tensorflow import keras\n",
    "from keras.utils import pad_sequences\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical, pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"hf://datasets/gabrielmbmb/text-generation-distilabel-ray/data/train-00000-of-00001.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 327 entries, 0 to 326\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   instruction          327 non-null    object\n",
      " 1   completion           327 non-null    object\n",
      " 2   meta                 327 non-null    object\n",
      " 3   generation           327 non-null    object\n",
      " 4   distilabel_metadata  327 non-null    object\n",
      " 5   model_name           327 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 15.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          completion  \\\n",
      "0  Denote the number of chocolates each person ha...   \n",
      "1  Elon Musk hires a team of experts to build the...   \n",
      "2  Clerk: How are you doing today?\\nCustomer: Gre...   \n",
      "3  The sun and the moon, the guards from the sky\\...   \n",
      "4  No, Searle does not believe that AI can think....   \n",
      "\n",
      "                                  processed_messages  \n",
      "0  denote number chocolate person letter first na...  \n",
      "1  elon musk hire team expert build ultimate yach...  \n",
      "2  clerk today customer great im buying grocery c...  \n",
      "3  sun moon guard sky one work day watch night ra...  \n",
      "4  searle believe ai think step step explanation ...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\92317\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\92317\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download necessary resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize stopwords and lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to preprocess individual texts (now working directly on strings)\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Lowercase the text\n",
    "    text = ''.join([char for char in text if char.isalnum() or char.isspace()])  # Remove punctuation\n",
    "    tokens = text.split()  # Tokenize by splitting\n",
    "    tokens = [word for word in tokens if word not in stop_words]  # Remove stopwords\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]  # Lemmatize the tokens\n",
    "    return ' '.join(tokens)  # Return the cleaned and lemmatized text\n",
    "\n",
    "# Apply the preprocessing function directly to the 'completion' column\n",
    "df['processed_messages'] = df['completion'].apply(preprocess_text)\n",
    "\n",
    "# Check the results\n",
    "print(df[['completion', 'processed_messages']].head())  # Display the processed messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completion\n",
      "<class 'str'>    327\n",
      "Name: count, dtype: int64\n",
      "0    Denote the number of chocolates each person ha...\n",
      "Name: completion, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Add this to verify that 'completion' has the correct structure\n",
    "print(df['completion'].apply(lambda x: type(x)).value_counts())  # Check types of data in 'completion'\n",
    "print(df['completion'].head(1))  # View one example of 'completion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    denote number chocolate person letter first na...\n",
      "1    elon musk hire team expert build ultimate yach...\n",
      "2    clerk today customer great im buying grocery c...\n",
      "3    sun moon guard sky one work day watch night ra...\n",
      "4    searle believe ai think step step explanation ...\n",
      "Name: processed_messages, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['processed_messages'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 327 entries, 0 to 326\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   instruction          327 non-null    object\n",
      " 1   completion           327 non-null    object\n",
      " 2   meta                 327 non-null    object\n",
      " 3   generation           327 non-null    object\n",
      " 4   distilabel_metadata  327 non-null    object\n",
      " 5   model_name           327 non-null    object\n",
      " 6   processed_messages   327 non-null    object\n",
      "dtypes: object(7)\n",
      "memory usage: 18.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words: 4215\n",
      "{'charise', 'planner', 'yard', 'paragraph', 'interference', 'human', '47', 'corporate', 'capitola', 'cheer', 'dazzling', 'lower', 'desert', 'doubledigit', 'applied', 'extreme', '10082018', 'key', 'specie', 'criterion', 'yeah', 'given', 'stumble', 'einstein', 'il', 'bud', 'groundbreaking', 'saul', 'huge', 'jawdropping', 'rye', 'musk', 'diverse', 'sector', 'done', 'pan', 'solution', 'na', 'symbolizes', '230330', 'muscle', 'forest', 'ring', 'mignon', 'program', 'country', 'binbash', 'steamed', 'lightfilled', 'correlation', 'provide', 'lake', 'elegant', 'work', '144', 'lucky', 'tenderness', 'reconstruct', 'amazigh', 'conversation', 'calculate', 'equipment', 'mathematics', 'submodalities', 'personid', 'burnt', 'dea', 'connecting', 'httpswwwoverleafcomlatextemplatesocencfdarticletemplatemtpnnssgzjzw', 'terror', 'dautres', 'paperlined', 'offensive', 'access', 'distributed', 'manuel', 'payment', 'microsoft', 'hook', 'turkey', 'rival', 'disposition', 'runner', 'enforce', 'buyer', 'spaceship', 'finger', 'sharing', 'diagnose', 'network', 'mischancethe', 'merge', 'prefer', 'tbduser', 'massage', 'band', 'straight', 'laguna', 'opening', 'cancer', 'surprise', 'sequential', 'code', 'rep', 'engineering', 'capture', 'swallowing', 'find', 'fulfill', 'litter', 'america', 'loud', 'medium', 'meditation', 'created', 'dormant', 'x', 'book', 'changed', 'artist', 'santos', 'swimming', 'violet', 'floorplan', 'modeling', 'linking', 'sweatshirt', 'lovely', '2218', 'pull', 'html', '9inch', 'showed', 'angle', 'swished', 'steak', 'calling', 'induct', '12062020', 'fdb3ae', 'httpsstackoverflowcomquestions15292278howdoiremoveanarrayitemintypescript', '6th', 'washing', 'style', 'constitution', 'greensborotriad', 'diagnosed', 'leaf', 'lucifer', 'fewer', 'seen', 'laid', 'overview', 'lie', 'definitely', 'fur', 'scaling', 'set', 'used', 'quit', 'built', 'canyon', '2500', 'sentence', 'x12', 'research', 'striker', 'retrieve', 'sprit', 'men', 'mel', 'employment', 'idiot', 'champion', 'unscathed', 'flake', 'starter', 'furoshiki', 'numbersi', 'unexpected', 'oled', 'rand', 'tournament', 'relating', 'buffalo', '2017', 'attracts', 'con', 'arent', 'pageant', 'spacious', 'colored', 'noticed', 'encinitas', 'renewal', 'tree', 'absorption', 'wish', 'barcelona', 'lewis', 'log', 'kindly', 'parsing', 'inch', 'typography', 'setting', 'brakeout', 'texttotext', 'excited', '103', 'shore', 'villa', 'oop', 'world', 'saving', 'volt', '7', 'api', '237101', 'mystical', '100ohm', 'professor', 'minimization', 'cause', 'saintly', 'antoni', 'dreamed', 'dam', 'snack', 'commit', 'anyone', '34', 'wtv', 'differ', 'hotel', '134', 'kidss', 'shape', 'stuff', 'distinctive', 'intensity', 'sick', 'term', 'aim', 'beyond', 'heat', 'seeing', 'spare', 'qa', 'overall', 'dataset', 'emphasise', 'reasonable', 'exceptional', 'merzouga', '10k', 'thanks', 'nicholas', 'add', 'knife', 'matilda', 'result', 'full', 'approach', 'inviting', 'turf', 'rigid', 'projectwere', 'mature', 'sand', 'interned', 'bake', 'ornamentation', 'gardening', 'distractible', 'positive', 'culture', '101', 'library', 'flour155', 'night', 'acoustic', 'cozy', 'b', 'ending', 'fewshot', 'say', 'earning', 'denver', 'tubmate', 'specialization', 'colourful', 'bay', 'deconstruct', 'clearly', 'stage', 'forbes', 'william', 'workshop', 'reduction', 'buzzing', 'vanilla', 'premium', 'physical', 'lloris', 'regret', 'tight', 'httpsopenspotifycomplaylist37i9dqzf1dx9xifqufvzm4', 'christian', '17', 'brief', 'contributes', 'ancient', 'bucked', 'kneetochest', 'settle', 'chocolate', 'nutty', 'calculates', 'venture', 'honeymoon', 'determined', 'staffed', 'whole', 'conqueror', 'found', 'upon', 'pane', 'packed', 'golden', 'sagrada', 'disruptive', 'creamy', 'rest', 'instagram', 'overengineered', 'collection', 'occurring', 'mosque', 'sleep', 'similar', 'request', 'five', 'skewer', 'rescue', 'exit', '5year', 'swank', 'interact', 'failed', 'pasta', 'engineer', '703', 'beachy', 'finally', 'sleeping', 'society', 'crucial', 'powerful', 'specific', '3minute', 'shetty', 'tub', 'promotes', 'ben', '165924789', 'spider', 'nausea', 'chemistry', 'spring', 'catch', 'shown', 'relatively', 'art', 'water', 'legal', 'tbds', 'couldnt', 'musician', 'juice', '01', 'calculus', 'setfen', 'dressing', 'banana', 'rangek', 'latin', 'purrfect', 'sexual', 'win', 'synonym', 'mkdir', 'backend', 'rivia', 'onelove', 'career', 'essential', 'solved', 'camera', 'rat', 'gracefully', 'mango', 'locale', 'string', 'countless', 'turn', 'compete', 'although', 'squad', 'kohl', 'vacuum', 'duct', 'actually', 'written', 'vega', 'csv', 'subsection', '2022', 'fbdf74', 'aws', 'amazoncommercial', 'pas', 'qty', 'dining', 'knight', '20', 'whatever', 'disneyland', 'girl', 'iceboxcooler', 'careful', 'element', 'tolkien', 'click', 'nearby', 'crosstask', 'valpolicella', 'sun', 'technique', 'ferris', 'next', 'stepped', 'sauce', '096', 'accept', 'complete', 'annie', 'workflow', 'performed', 'summer', 'joy', 'disease', 'proud', 'near', 'upstairs', 'grease', 'fatigue', 'metabolism', 'master', 'nom', 'predilection', 'without', 'explosion', 'ncis', 'music', 'architecture', 'blocker', 'sum0', 'child', 'noise', 'determine', 'score', 'onoff', 'est', 'spouse', 'q1', 'cm', 'half', 'n2', 'powerbi', 'overnight', 'mountain', 'consistently', 'chich', '201112', 'jk', 'paste', 'skill', '013', 'fsl', 'dangerous', 'person', 'alone', 'started', 'short', 'sauvignon', 'httpsbeetsreadthedocsioenv1314pluginsduplicateshtml', 'dock', 'linguistically', 'adventurous', 'bennett', 'vibe', 'feedback', 'anaheim', 'post1982', 'gorge', 'mystique', 'maybe', 'roy', 'chapter', 'cloth', 'parentselector', 'cacophony', 'strasbourg', 'social', 'gas', 'closely', 'trick', 'conditional', 'boat', 'online', 'michigan', 'interviewer', 'suggested', 'busty', 'express', 'peaky', 'construction', 'foot', 'dc', 'newchessgame', 'nums', 'mickey', 'application', 'dishwasher', 'circle', 'nice', 'stress', 'captain', 'chunks110', 'geography', 'throne', 'considering', 'actor', 'extensive', 'expression', 'discipline', 'appear', 'cavern', 'thrilling', 'impactful', 'path', 'might', 'tsl2561', 'imposing', 'marseille', 'town', 'toxic', 'expensive', 'trust', 'wasted', 'santa', 'swallow', 'gilley', 'acidic', 'placed', 'dream', 'horse', 'splitting', 'médecine', 'time', 'rwaltz', 'wear', 'nearly', 'curious', 'supporting', 'tear', 'newdirectory', 'reference', 'making', 'gained', 'identity', 'walk', 'subsequence', 'thanksgiving', 'gutter', 'lecture', 'split', 'rapid', 'capable', 'wherever', 'wake', 'pride', 'faded', 'dip', 'literacy', 'motivated', 'participating', 'upscale', 'requirement', 'understanding', 'fruit', 'showing', 'ultra', 'exchange', 'gift', 'entry', 'starting', 'amarone', 'diversity', 'selector', 'managing', 'solarpowered', 'standclearmedium', 'store', 'comma', 'layout', 'salary', 'farm', 'outstanding', 'leadership', 'wash', 'cabernet', 'dawn', '14', 'singlelevel', 'according', 'monica', 'poet', 'stainless', 'budget', 'goal', 'forever', 'bat', 'httpswwwoverleafcomlatextemplateshomeworksolutionsxykkzgnbzmxp', 'funchal', 'germany', 'adversity', 'x0', 'quickly', 'humiliating', 'createframe', 'repository', 'happened', 'fellowship', 'disk', 'detection', 'smoky', 'hunt', 'pointer', 'dentition', 'faithful', 'factor', 'role', 'landscaped', 'related', '9v', 'boss', 'cuttingedge', 'material', 'firm', 'jay', 'show', 'seal', 'fewshotqa', 'barely', 'sum', 'fast', 'combining', 'challenging', 'lord', 'consider', 'staff', 'flexible', 'grocery', 'wax', 'pleasantry', 'guava', 'pour', 'statistic', 'multiplayer', 'demonstrated', 'anything', 'marino', '350f', 'asset', 'revolutionary', 'visitor', 'skyscraper', 'c', 'causing', 'manager', 'instantly', 'du', 'blanket', 'bright', 'problemsbe', 'toggle', 'invader', 'upload', 'put', 'vegetarian', 'us', 'light', 'organizing', 'intense', 'mass', 'allpurpose', 'httpskoalasreadthedocsioenlatestreferenceapidatabrickskoalasdataframedropduplicateshtml', 'stillactive', 'bedroom', 'nvme', 'needed', 'paper', 'youre', 'semisweet', 'probably', 'following', 'picnic', 'adapting', 'miss', '291548376', '16', 'nectar', 'denote', 'beat', 'sunbathing', 'deep', 'prepare', '6', '50', 'composition', 'rewatch', 'largest', 'jack', 'suppresses', 'plot', 'defect', 'almost', 'tied', 'multitask', 'treat', 'aglow', 'international', 'discrimination', 'temporomandibulaire', 'cooking', 'wrong', 'edegg3g2', 'practiced', 'wall', 'seo', 'harriet', 'pitcher', 'opts', 'start', 'silhouetted', 'calendar', 'chelsea', 'returned', '1791', 'analyzed', 'cone', 'removing', 'issueto', 'soon', 'mouth', 'answering', 'usepackagexskak', 'dijk', 'talented', 'neoclassical', 'cocktail', 'app', 'encountered', 'rating', 'img', 'loses', 'sudan', 'analysis', 'wellwritten', 'également', 'enlightenment', 'regulator', 'listening', 'tagine', 'york', 'highly', 'icon', 'serving', 'clock', 'better', 'daily', 'garage', 'workspace', 'uncertain', 'site', 'sorry', 'pizzeria', 'seems', 'get', 'representative', 'didnt', 'eg', 'fantasy', 'seize', 'gateway', 'argument', '2747', 'huberman', '24hours', 'complexity', 'angel', 'nobody', 'patrol', 'use', 'friend', 'sweden', 'language', 'largescale', 'hundred', 'scene', 'ski', 'resulting', 'agile', 'call', '27', 'batted', 'gestion', 'price', 'resource', 'probability', 'raised', 'stock', 'ranging', 'exported', 'wire', 'trailblazing', 'ounce', 'glow', 'geyser', 'insisted', 'beautiful', 'autoregressive', 'photo', 'asked', 'pujols', 'daisy', 'salmon', 'aging', 'baking', 'cookie', 'standard', 'coloring', 'loose', 'survive', 'university', 'aspect', 'delicate', 'security', 'bee', 'toward', 'based', 'type', 'order', '95', 'noun', 'stop', '41', 'life', 'pyramid', 'teacher', 'transformed', 'anthony', 'fortunately', 'snap', 'nerve', 'g32', 'tubing', 'smoking', 'generally', 'scroll', 'sad', 'infecting', 'soonthis', '1099', 'movement', 'pet', 'generated', 'sap', 'costume', 'algorithm', 'oblike', 'laundry', 'edible', '22k', '35', '73', 'complimented', 'connue', 'field', 'heart', 'overleaf', 'grant', 'encoder', 'dear', 'baker', 'lakers', 'lot', 'metaphor', '93', 'released', '975', 'sienna', 'switched', 'custom', 'struggling', 'invertebrate', 'generate', 'meth', 'zeroll', 'g3g2', 'spread', 'contemporary', 'numsi', 'mad', 'industry', '2tb', 'wicked', 'specialist', 'ounila', 'sunny', '4hole', 'computer', 'guidebook', 'pointing', 'formed', 'seeker', 'benchmark', '1215', 'thus', 'sail', 'enddocument', 'document', 'honored', '1065fszt', 'customer', 'drop', 'lab', 'jewel', 'carry', 'waving', 'captivating', 'reelection', 'share', 'selection', 'equivalently', 'explanation', 'still', 'heartwarming', 'particularly', 'fan', 'assisted', 'colleague', 'greenhouse', 'enough', 'nptes', 'nozzle', 'w', 'ga', 'figured', 'gather', 'describes', 'freadlines10', 'naomi', 'recognizable', 'erg', 'crimson', 'clarke', 'destruct', 'pytest', 'importing', 'fielder', 'mild', 'hank', 'leveling', 'blitzreading', 'retail', 'past', 'gone', 'multiplication', 'consolelogi', 'mockingbird', 'assign', 'trouble', 'ad', 'teamwork', 'metatuning', 'nodding', 'documentqueryselectorhelpcentre', 'chucked', 'via', 'meeting', 'controversial', 'luxury', 'added', 'sunshine', 'nozzel', 'police', 'move', 'min', 'entertaining', 'automated', 'plantbased', 'face', 'limit', 'que', 'follow', 'n1', 'plant', 'interval', 'blind', 'confidence', 'extraordinary', 'website', 'opportunity', 'selfdefrosting', 'box', 'wellestablished', 'pod', 'bitcoin', 'skinny', 'prove', 'flash', 'stance', 'hear', '456739812', 'dont', 'bend', 'area', 'oblic', 'play', 'epagov', 'psychology', 'island', 'ibayam', 'length', 'yesnonot', '010323', 'ointment', 'spacetime', 'correct', 'force', 'neil', 'cheesy', 'easy', 'demo', 'american', 'jeter', 'jdk7', 'hypothermia', 'couple', 'fume', 'nov', 'inclusive', 'woke', 'honest', 'almond', 'touched', 'humor', 'hi', 'straightforward', 'using', 'q2', 'babbling', 'oblīquus', 'httpsorange3textreadthedocsioenlatestwidgetsduplicatedetectionhtml', 'highlight', 'adafruits', 'man', 'allowing', 'hold', 'sign', 'moon', 'formal', 'proportion', 'fluidfilled', 'n', 'seaport', 'ducked', 'beeswax', 'trip', 'ngo', 'capistrano', 'manchester', 'beginning', 'broad', 'longer', '8666', 'christmas', 'recommend', 'coaster', 'select', 'password', 'multihop', 'brown', 'input', 'blue', 'k22k1', 'selfcaterers', 'c7', 'flow', 'single', 'tea', 'techdocumentation2wwwdotexampledotcom', 'disney', 'dialogue', 'surrounding', 'healthier', 'picked', 'thicker', 'isnt', 'maintaining', 'trivial', 'aquarium', 'migrate', 'compound', 'documentcreateelementiframe', 'jean', 'bingewatching', 'baggy', 'revenge', '5', 'exploring', 'entertainment', 'decoder', 'touch', 'bottom', 'dark', '23', 'businessstrategy', 'door', 'ave', 'including', 'dishtraditional', 'agave', 'rich', 'success', 'lesson', 'ago', 'growing', 'averagenumbers', 'sport', 'childrens', 'greycolored', 'print', 'chicken', 'guidance', 'resistor', 'womeninstem', 'parent', 'leave', 'winco', 'viewer', 'helping', 'french', 'flame', 'could', 'sunset', 'flavor', 'emphasizes', 'researched', 'shrink', 'wdesigner', 'totalofnumbersk', 'narrator', 'phonestablets', 'changing', 'david', 'black', 'heritage', 'gaudí', 'remaining', 'trunchbull', 'hammerthrowing', 'confident', 'diameter', 'rnn', 'credit', 'hit', 'holder', 'speed', 'gamechanging', 'center', 'talk', 'risk', 'buzzer', 'administrative', 'learn', 'proposed', 'sincerest', 'onto', 'handle', '547316298', 'albert', 'castle', 'kitchen', 'supplier', 'codified', 'friendly', 'drive', 'therefore', 'formation', 'soldiering', 'installing', 'thin', 'script', 'tableau', 'chinese', 'pool', 'eventually', 'creating', 'across', 'attributed', 'combination', 'indicate', 'second', 'nightmare', 'astonishing', 'charge', 'tender', 'typed', 'food', 'towards', '¾', 'matildas', 'intrpruhtayshnz', 'fridge', 'unhealthy', 'stating', 'chloride', 'pottery', 'file', 'emailing', 'hello', 'demonstrate', 'possible', 'curveball', 'provides', 'fundamental', 'numslength', 'compliance', 'required', 'bruschetta', 'heard', 'branch', 'egg', 'lowconfidence', 'entered', '2099', 'multicolor', 'denmark', 'ed', 'shopper', 'candidate', 'englober', 'mini', 'dealing', 'space', 'sewing', 'ice', 'debug', 'outcome', 'smart', 'basilica', 'mechanism', 'define', 'grilled', 'environmentally', 'tracking', 'bathroom', 'indoor', 'senegal', 'honey', 'median', 'mark', 'fun', 'loved', 'flour', 'super', 'consumption', 'linked', 'fintech', 'fort', 'conflict', 'remote', '63', 'pinkman', 'petroleumbased', 'salesman', 'bring', 'unique', 'agency', 'fade', 'object', 'market', 'launched', 'however', 'x34', 'happen', 'medina', 'article', 'communicate', 'bending', 'carrying', 'policy', 'harder', 'league', 'tradition', 'interpretation', 'borrowed', 'isprimen', 'marketer', 'car', 'macroeconomic', 'offering', 'efficiency', 'patrick', 'blowing', 'giant', 'gayles', 'distraction', 'orange', 'pouring', 'handsome', 'csvfiletxt', 'neurotransmitter', 'stakeholder', 'cash', 'painting', 'backup', 'sparked', 'messaging', 'unbeknownst', '54', 'httpsdoiorg1048550arxiv170603762', 'whittier', 'praticien', '411', 'auto', 'earth', 'unknown', 'debugging', 'consume', 'idiotic', 'mystic', 'clear', 'manually', 'coding', 'extra', 'california', 'part', 'wow', 'led', 'great', '700', 'ongoing', 'color', 'amino', 'nowhere', 'buccale', 'court', 'beast', 'comfortable', 'keep', 'puzzle', 'switch', 'oct', 'fascinating', 'observatory', 'connect', 'deer', 'throwing', 'who', 'f', 'happily', 'wine', 'shutter', 'norton', 'paraffin', '18', 'rodgers', 'samsung', 'frostbite', 'bathing', 'strike', 'loudly', 'discover', 'hard', 'summarization', 'addcontentsline', 'chatterbox', 'jsons', 'romanian', 'environmental', 'living', 'shoot', 'freezing', 'soap', 'blockchain', '25052040910909190909325052040910909190909', 'profit', 'tattoo', 'preheated', 'investment', 'interchangeable', 'san', 'expects', 'hitting', 'receptacle', 'funny', 'twisty', 'fen', 'donatella', 'sectionintroduction', 'hitchhiker', 'audience', 'hoard', 'dune', 'shaming', 'live', 'one', 'beach', 'fit', 'reducing', 'mazelike', 'engine', 'family', 'applies', 'checkout', 'curve', 'dual', 'snowing', 'provided', 'escalates', 'fill', 'habit', 'santeclaus', 'cakier', 'tourist', 'significant', 'productivity', 'repair', 'richly', 'container', 'extremely', 'seafront', 'spicy', 'resolved', 'verb', 'til', 'documentary', 'hence', 'gatsby', 'check', 'secure', 'passing', '30', '7777777', 'sectionsecond', 'instance', 'hide', 'icecream', 'west', 'evaluation', 'original', 'id', '123', 'pant', 'tableofcontents', 'vessel', 'tube', 'texan', 'daline', 'chatty', 'wide', 'monument', 'building', 'flower', 'unbelievably', 'else', 'route', 'genius', 'source', 'normal', 'clement', 'best', 'value', 'crowd', 'slope', 'king', 'fueled', 'national', 'alien', 'told', 'jagged', 'board', 'introduces', 'recover', 'email', 'signed', 'rachel', 'outweigh', 'sell', 'various', 'ede', 'deeper', 'traffic', 'negative', 'melted', 'white', 'sight', 'insatiable', 'instruction', 'card', 'raw', 'cirq', 'protected', 'automatically', 'sorting', 'slowly', 'integer', 'inequality', 'gotten', 'diem', 'atlas', 'line', 'kolby', 'entranced', 'cooky', 'lover', '783162549', 'jan', 'chill', 'grass', 'later', 'le', 'overrated', 'foliage', 'environment', 'mingnor', 'brick', 'fewjoint', 'obtain', 'brain', 'processing', 'grate', 'sat', '750000', 'ended', 'shifting', '980', 'terry', 'eight', 'news', 'pizza', 'terrain', 'mouse', 'office', 'though', 'butter', 'ocean', 'emma', 'hot', 'regard', 'sure', 'away', 'rising', 'blood', 'conjunction', 'left', 'patience', 'ac1', 'sometimes', 'qualified', 'harmful', 'disadvantage', 'tell', 'dragster', 'financial', 'pg13', 'reproduce', 'crater', 'pharmacy', 'generative', 'branche', 'manner', 'childish', 'france', 'pump', 'relationship', 'relation', 'make', 'fiveandahalf', 'degree', 'cheerful', 'couer', 'marketing', 'ornament', 'purchase', 'invite', 'ankle', 'core', 'blackkklansman', 'albequerque', 'evolution', 'peaceful', '2', 'stick', 'widely', 'iteration', 'selfcentered', 'd3dd2', 'plenty', 'ability', 'historic', 'christie', 'stroke', 'jacob', 'economist', 'covering', 'trash', 'hesitate', 'fashion', 'bone', 'switzerland', 'stunning', 'novik', 'fly', 'graduate', 'feature', 'appliance', 'playing', 'sandwich', '1758', 'solidifies', 'harmony', 'interested', 'superiore', 'toflexibility', 'staten', 'called', 'skiable', 'explain', 'apply2gradschool', 'giving', 'httpssqlparsereadthedocsioenlatestanalyzing', 'h', 'lone', 'd3', 'zinc', 'burglar', 'combined', 'statement', 'rug', 'producing', 'serious', 'division', 'sie', 'pat', 'whale', 'ted', 'settling', 'pro', 'defines', 'finish', 'eye', 'funeral', 'silver8oz9', 'tail', 'worldchanging', 'someone', 'error', 'lack', 'toning', 'recycle', 'insurance', 'swooped', 'dilemma', 'searching', 'help', 'peace', 'universe', 'kid', '1230', 'descended', 'economic', 'tool', 'quiz', 'skipped', '66', 'scifi', 'shaker', 'binary', 'indooroutdoor', 'happy', 'strawberry225', 'usepackagetitlesec', 'quieter', 'minimum', 'bamboo', 'cauliflower', 'wild', 'user', 'lighting', 'ticket', 'common', 'magnetic', 'failing', 'candy', 'chunk', 'encourage', 'subscription', 'process', 'vaswani', 'sydney', 'git', 'analyze', 'commodity', 'rehab', 'gun', 'classmate', 'rampart', 'butter115', 'storm', '2734', 'within', 'm34', 'hopping', 'suit', 'pink', 'chicago', 'branchname', 'sample', 'free', 'studio', 'aboard', 'reminder', 'experiment', 'equality', 'plan', 'season', 'match', 'brother', 'pie', 'size', 'cake', 'responsible', 'always', 'largely', 'person2', 'shed', 'inability', 'able', 'support', 'resignation', 'chum', 'front', 'arcing', '260', 'bordeaux', 'picture', 'fa', 'flee', 'dec', 'aroma', 'handicapped', 'clean', 'gorgeaït', 'soup', 'fair', 'donemeaning', 'stone', 'otherwise', 'im', 'cry', 'science', 'en', 'beginner', 'unesco', 'r', 'methylated', 'username', 'triggered', 'corresponds', 'highpaying', 'mean', 'handling', 'millennium', 'printed', 'stoked', 'distress', 'interior', 'heist', 'tsouthwind', 'read', 'here', 'literature', 'representation', 'outer', 'macbook', 'roar', 'blackberry', 'guiding', 'vector', 'storytelling', 'sailing', 'diego', 'newport', 'directly', 'luck', 'campaign', 'reduce', 'ir', 'contain', 'brand', 'gradschoolprep', 'signature', 'labeling', 'artificial', 'hope', 'wrap', 'womenscience', 'stove', 'coast', 'printi', 'fahrenheit', 'minute', 'receiving', 'speaking', 'magic', 'jolla', 'reserve', 'bibliography', 'rowling', 'journalism', 'metaphoric', 'equal', 'announce', 'morning', 'range10', 'boardwalk', 'humanity', 'panel', 'discrediting', 'gogradschool', 'maddow', 'placeholder', 'since', 'teaspoon', 'response', 'version', 'display', 'liquid', 'bengal', 'third', 'blvd', 'partial', 'protagonist', 'bulldozer', 'hid', 'appointed', 'pollute', 'healthy', 'wonderful', 'upcoming', 'tablespoon', 'form', 'xx', 'livestock', 'lady', 'ich', 'concluding', 'sugar165', 'series', 'experience', 'necessary', '180c', 'exploratory', 'k', 'important', 'availability', 'famous', 'measurement', 'audio', 'interface', 'foreign', 'larticulation', 'perform', 'deduct', '14th', 'curiosity', 'durational', 'far', 'fact', 'wolf', 'stealing', 'funished', 'know', 'scientist', 'exampleframesrc', 'group', 'taken', 'remove', 'coffee', 'column', 'harry', 'cant', 'new', 'strlength', 'charlotte', 'snow', 'defined', 'creeping', 'ahead', 'attribute', 'condition', 'visit', 'crab', 'public', 'charles', 'bar', 'er', 'talking', 'smell', 'surveillance', 'delivering', 'small', 'opened', 'going', 'directory', 'chair', 'barista', 'dcg', 'mutated', 'interview', 'mission', 'death', 'neuroscience', 'i10', 'spam', '109253710118', 'joining', 'affection', 'maverick', '3000', 'innate', 'illness', 'hunger', 'caseinsensitive', 'sidewalk', 'keywords', 'httpsdomareadthedocsioenlatestsql', 'hour', 'transfer', 'thrill', 'motion', 'gaming', 'slider', 'proof', 'allow', 'lighten', 'complexe', 'variety', 'djemaa', 'entertain', 'mnemonty', '238900', 'quarter', 'transduction', 'supposedly', 'perimeter', 'supply', 'petfriendly', 'federal', 'recommended', 'thankful', 'conduct', 'restaurant', 'stempodcast', 'sliced', 'warmth', 'student', 'fine', 'getting', 'except', 'quick', 'howling', 'arrive', 'deadlifts', 'supernerd', 'diet', 'need', 'begindocument', 'admits', 'vengeance', 'block', 'suggests', 'snowpocalypse', 'credential', 'incongruous', 'worthiness', 'de', 'spend', 'lightly', 'offense', 'amenity', 'infused', 'summarize', 'park', 'plane', 'farewell', 'weve', 'lined', 'neutral', 'enjoy', 'insert', 'guard', 'let', 'professional', 'eriksen', 'stand', 'november', 'train', 'breaking', 'bonfire', 'station', 'loss', 'avoid', 'published', 'wait', 'football', '04mm', 'azure', 'cold', 'hotpotqa', 'orca', 'dcgb32', 'worn', 'ready', 'neural', 'dan', 'regular', 'alive', 'orc7', 'asymptomatic', 'fellow', 'procrastinate', 'maze', 'shared', 'transverse', 'nervous', 'checked', 'weird', 'wed', 'maintain', 'rustling', 'readily', '36', '4x4', 'yes', 'lime', 'residence', 'adorable', 'roller', 'sturdy', 'tuning', 'seatingwaiting', 'wedding', 'topper', 'give', '68', 'moisture', 'hang', 'device', 'build', 'beauty', 'former', 'wheel', 'jet', 'wanted', 'u', 'rowan', 'frightened', 'mile', 'assigns', 'sleeve', 'situation', 'emotion', 'voltage', 'transition', 'product', 'introduction', 'room', 'interesting', 'forgot', 'creates', 'break', 'farnsworth', 'catcher', 'enjoyed', 'slip', 'management', 'cooked', 'stranded', 'gpus', 'clerk', 'linear', 'abduct', 'strategy', 'vanishing', 'inner', 'trade', 'fainting', 'létude', 'choose', 'maui', 'ashish', 'pratchett', 'side', 'colorful', 'cider', 'company', 'story', 'speak', 'managed', 'model', 'amid', 'driving', 'grown', 'contaminant', 'increment', 'along', 'gating', 'lux', 'gray', 'wealthier', 'old', 'onepot', 'peut', 'premise', 'aluminum', 'rated', 'figmadoc1wwwdotexampledotcom', '104', 'principal', 'geralt', 'natural', 'afternoon', 'savannah', 'main', 'rather', 'mode', 'phone', 'thank', 'around', 'a2', 'charm', 'pressure', 'food52', 'malachi', 'running', 'parameter', 'ive', 'luxurious', 'outdated', 'opposite', 'today', '10', '639', 'look', 'trusty', 'pier', 'strolling', 'holding', 'overmix', 'chickfila', '45', 'design', 'gc', 'item', 'silicone', 'completed', 'deserve', 'functionality', 'x2', 'whats', 'brady', 'lose', '8', 'chili', 'throughout', 'parchment', 'addicted', 'logically', 'jsondict', 'software', 'rotate', 'cherish', 'cover', 'lineup', 'journal', 'blinder', 'holiday', 'professionally', 'bed', '29', 'ecology', 'thinking', 'manure', 'realized', 'preference', 'recreational', 'leg', 'visual', 'chance', 'musical', 'appelé', 'yacht', 'brees', 'represents', '30c86f', 'skin', 'juan', 'dramatic', 'party', 'count', 'développement', 'digitizing', 'belief', 'recapping', 'founded', 'dentisterie', 'person3', 'reached', 'cove', 'fossil', 'sending', 'shot', 'general', 'dahmer', 'consiste', '¼', 'plucked', 'presented', 'redshift', 'slave', 'tasty', 'improvisation', 'outdoor', 'character', 'monsterhunter', 'glad', 'portable', 'committed', 'spade', 'star', 'facetoface', 'among', 'hotheaded', 'vowel', 'wrapping', 'quirky', 'dead', 'suffering', 'remarkably', 'contextualized', 'techdocumentation1wwwdotexampledotcom', 'notified', 'hill', 'default', 'ob', 'xit', 'sawtooth', 'sweeping', 'stargazing', 'n1th', '40', 'dopamine', 'sweet', 'either', 'ruth', 'dragon', 'pretraining', 'fling', 'fewclue', 'took', 'problem', 'compared', 'avocado', 'capacity', 'zero', 'moreover', 'join', 'acronym', 'prejudice', 'purdie', 'daphnia', '120yard', 'mexico', 'brings', 'murdered', 'writing', 'quartz', 'known', 'filet', 'e', 'guide', 'd2', 'sweating', 'kmart', 'n2th', '64', 'undercover', 'identify', 'vt', 'momentary', 'searle', 'text', 'even', 'effort', '2k', 'achieve', 'thumb', 'theyve', 'podcasts', 'discusses', 'basis', 'module', 'golang', 'chase', 'garnish', 'journey', 'four', 'oz', 'homemade', 'pen', 'south', 'vary', 'cursor', 'traveler', 'takeaway', 'mere', 'organization', 'highend', 'street', 'eater', 'washed', 'lyon', 'slid', 'tbdaction', 'approached', 'bank', 'long', 'eagerness', 'grazing', 'strictly', 'gnaoua', 'potato', 'sqrt6', 'sends', 'particular', 'criminal', 'effectively', 'located', 'watching', 'arrived', 'objectsequals', 'endusers', 'john', 'orchestration', 'easiest', 'acting', 'prompt', '972853164', 'temperature', 'race', 'incident', 'maximizing', 'technology', 'despite', 'snowy', 'billing', 'activity', 'ovenfried', 'deviled', '81', 'gaiman', 'beverage', 'involved', 'disaster', 'resort', 'savour', 'fearless', 'mixture', 'range2', 'businessgrowth', 'agreement', 'head', 'global', 'falling', 'place', '9n', 'scale', 'independence', 'pitch', 'maintains', 'favor', 'adopt', 'foundational', 'cabin', 'zeroshot', 'haddou', 'innovative', 'rafting', 'ensure', 'quite', 'porous', 'qi', 'k2', 'reusable', 'sits', 'dentaire', 'cared', 'bowl', 'every', 'ft', 'woman', 'dutch', 'static', 'opinion', 'ingredient', 'iron', 'difficult', 'temporary', 'washburn', 'passion', '20042018', '5415', 'label', 'quantity', 'warning', 'followed', 'turbulent', 'dictionary', 'icemaker', 'review', 'thereby', 'plus', 'crown', 'glowing', 'twenty', 'abrasive', 'designer', 'pricing', 'method', 'altalternatetext', 'close', 'randand', 'missed', 'packing', 'python', 'textile', 'zelato', 'walter', 'responsibility', 'moving', 'testing', 'hoped', 'really', 'earn', 'aït', 'sql', 'knitting', 'chaotic', 'attention', 'redundant', 'level', 'monthly', 'gbcdd', 'adaptive', 'jesses', 'cool', 'begin', 'et', 'bullet', 'riad', 'information', 'tbdresource', 'organized', 'srcurl', 'entrance', 'trail', 'schedule', 'tin', 'service', 'grow', 'tormenting', 'oak', 'heaven', 'creature', 'seem', 'meadow', 'completion', 'tag', 'worry', 'productive', 'q5', '28042017', 'apple', '328497651', 'uv', 'elli', '11', 'rogan', 'home', 'mercados', 'puddle', 'destem', '2024', 'efficiently', 'narrow', 'decided', 'lowercase', 'weight', 'gelato', 'diy', 'gothic', 'requested', 'engaging', 'finest', 'search', 'tattooing', 'sens', 'paid', 'involving', 'principle', 'authorgubert', 'json', 'shoe', 'current', 'ditch', 'augmentation', 'drilled', 'intn051', 'blacklist', 'due', 'steel', 'prepared', 'oxide', 'fibonacci', 'quiet', 'roll', 'already', 'lunch', 'flipside', 'status', 'delicious', 'consideration', 'liberty', 'drastically', 'acceptance', 'imagination', '296', 'exampleframestyledisplay', 'boost', 'anniversary', 'kidfriendly', 'peg', 'finished', 'grabbed', 'carbon', 'cutting', 'httpswwwoverleafcomlatextemplatespittstatephysicshomeworktemplatewdsxknmntnxk', '22', 'qatar', 'celsius', 'true', 'drinking', 'noten', 'oblique', 'emerged', 'structure', 'dried', 'merzougadades', '9', 'drew', 'thud', 'june', 'screen', 'brimming', 'demon', 'system', 'wrist', 'annoyance', 'goaloriented', 'parking', 'abdominal', 'ever', 'playboy', 'another', 'ultimate', '14yearold', 'httpsstackoverflowcomquestions19544452removelastitemfromarray', 'markdown', 'kale', 'adhere', 'savory', 'weather', 'decision', 'medical', 'archetype', 'toffeelike', 'nicer', '0', 'ten', 'yet', 'leaving', 'traveling', 'dishonoring', 'big', 'los', 'red', 'embrace', 'q3', 'evenly', 'variable', 'intrigue', 'waste', 'taco', 'frame', 'theme', 'depending', 'waited', 'boolean', 'house', 'march', 'courtesy', 'growth', '4', 'offer', 'consultancy', 'clay', '038mm', 'manipedi', 'revealed', 'number', 'magenta', 'prévention', 'elliptical', 'exampleframeid', 'mystery', 'optional', 'meat', 'sequence', 'riverline', 'mathlog10n', 'samesex', 'typing', 'solubility', 'bad', 'poetry', 'business', 'import', 'edge', 'matrix', 'usual', 'riggins', 'visualization', 'marketplace', 'adding', 'impact', 'entire', 'september', 'eggplant', 'jrr', '20c67f', 'partying', 'g', '100', '12', 'enroll', 'nature', 'solves', 'ensuing', 'shopping', 'mathlog103', 'final', 'buy', 'worked', 'domain', 'havent', 'balance', 'sort', 'got', 'ukrainian', 'large', 'verify', 'addcontentslinetocsectionunnumbered', 'merging', 'trucked', 'england', 'eating', 'think', 'clickbait', 'drug', 'cabinetry', 'assorted', 'raven', 'sink', 'title', 'sentiment', 'assumption', 'came', 'recreation', 'milk', '456789', 'effect', 'modular', 'c32', '1963', 'moveinready', 'stressful', 'cent', 'haart', 'zinfandel', 'spinning', 'traitement', 'yearly', 'southern', 'antagonizing', 'turned', 'community', 'rhythm', 'diabetes', 'speaker', 'epic', 'everyday', 'road', 'travel', 'voice', 'fire', 'containing', 'bora', 'exciting', 'threatened', 'explaining', 'copper', 'blueberry225', 'lived', '652', 'release', 'van', 'currently', 'chose', '1980s', 'employee', 'leading', 'redistribute', 'issued', 'merges', 'immediately', 'green', 'brook', 'longevity', 'destination', 'section', 'vest', 'hwy', 'acid', '1984', 'choice', 'symbolic', '3d', 'salad', 'sumsum', 'recommendation', 'recognize', 'acre', 'damage', 'jon', 'salty', 'netherlands', 'purpose', 'river', 'send', 'lit', 'trying', 'novel', 'da', 'lobster', 'reverse', 'occupation', 'relevant', 'httpsstackoverflowcomquestions3954438howtoremoveitemfromarraybyvalue', 'jump', 'caregiver', 'topic', 'crystal', 'maketitle', 'armband', '622', 'example', 'paint', 'planningdoc1wwwdotexampledotcom', 'whether', 'sorcerer', 'ainatebok', 'keeping', 'list', 'collaborative', 'stirfry', 'benefit', 'scope', 'tour', 'jumping', 'coordination', 'matter', 'substantial', 'elon', 'sounded', '25', 'strip', 'remain', 'battery', 'angeles', 'familia', 'stink', 'ripasso', 'funchalcottagescouk', 'flying', 'gear', 'jacket', 'last', 'mentor', 'stake', 'continued', 'taste', 'blank', 'bag', 'trophy', 'consuming', 'refund', 'printx', 'amazing', '396', 'g2', 'arrival', 'consistency', 'zesty', '665', 'gradually', 'resemble', 'beer', 'saying', 'shivering', 'donatellaemailcom', 'nextlevel', 'age', 'pathway', 'analyst', 'task', 'taking', 'sonoma', 'echo', 'independent', 'average', 'interrupted', 'especially', '899', 'titlesections', 'collaboratively', 'warm', 'strain', 'jane', '1311', 'chessboardsetfenr5k11b1p1pppp71p1q42p1r3pp4pqbbp2b1pr4r1k', 'nonnegative', 'flutter', 'assignment', '10092020', 'forced', 'glue', 'longest', 'joe', 'hire', 'waiting', 'change', 'village', 'major', 'knocking', 'option', 'laughed', 'belly', 'respectively', 'cigarette', 'majestic', 'douglas', 'pilers', 'cafe', 'everybody', 'button', 'event', 'iii', 'incorrect', '46', 'pipeline', 'committing', 'morocco', 'prompted', 'dirty', 'film', 'agenda', 'hey', 'dentiste', 'oh', 'bill', 'cannot', 'name', 'promise', 'ouarzazate', 'filetxt', 'facing', 'resolution', 'dominant', 'termite', '375', 'point', 'accomplish', 'spine', 'excelled', 'iframe', 'inputenter', 'sur', 'take', 'infamous', 'sky', 'playful', 'recently', 'carve', 'constructive', 'money', 'page', 'central', 'many', 'ball', 'sent', 'ghost', 'fresh', 'skating', 'bonsoir', 'address', 'earlier', 'rocket', 'girlfriend', 'disavow', 'bib', 'swaddling', 'gain', 'obstruct', 'blindtext', 'recycled', 'misfortune', 'shes', 'passionate', 'charger', 'esp32', '90', 'argentina', 'alarm', 'note', 'planet', '06', 'computational', 'unattractive', 'historical', 'def', 'regarding', 'internship', 'numberslength', 'multilingual', 'unnumbered', 'climax', 'mindtrap', 'considerable', 'squirrel', 'reaching', 'slight', 'behind', 'cut', 'special', 'contribution', 'finding', 'moment', 'gatsbys', 'aware', 'eternally', 'promotion', 'muffin', '49ers', 'sandra', 'classroom', 'avalanche', 'sympathetic', 'phoneme', 'opt', 'comedy', 'hand', 'stay', 'gently', 'reading', 'fundraiser', 'rash', 'amount', 'generalpurpose', 'meaningful', 'ii', 'translation', 'organisation', 'way', 'haddoumarrakech', 'b32', 'church', 'inconvenience', 'st', 'question', 'marker', 'increase', 'httpsstackoverflowcomquestions5767325howcaniremoveaspecificitemfromanarray', 'walt', 'scheme', 'fencing', 'purple', 'interest', 'cloud', 'headache', 'becoming', 'apend', 'httpsiterationutilitiesreadthedocsioenlatestgeneratedduplicateshtml', 'manage', 'tonal', 'europe', 'notice', 'fiction', 'terrace', 'protectionism', 'update', 'unclassasdate19710101', 'specializes', 'aroused', 'square', 'filter', 'economy', 'crust', 'selfmotivated', 'outside', 'resting', '500', 'journaling', 'volume', 'hole', 'terminal', 'mud', 'understand', 'documentation', 'violence', 'procrastinating', 'marrakechouarzazate', 'peeled', 'table', 'rate', 'dish', 'guardian', 'animal', 'ship', 'well', 'maker', 'giggle', 'training', '1', 'fatality', 'stalk', 'emphasize', 'ride', 'began', 'stomach', 'idea', 'nth', 'shining', 'backyard', 'landscape', 'optimization', 'slide', 'scheduled', 'baggier', 'looked', 'pop', 'declaration', 'menace', 'reader', 'wildland', 'submodality', 'interruption', 'tech', 'breakfast', 'anticipated', 'bilingual', 'duckling', 'skilled', 'tried', 'candle', 'cup', 'cedar', 'romantic', '½', 'galaxy', 'affluence', 'encouraging', 'spin', 'lb', 'department', 'personalized', 'previous', 'basin', 'a3a2', 'bouche', 'worth', 'root', 'greek', 'blooming', 'fl', 'inaccessibility', 'documentclassarticle', 'creatively', 'megacorporations', 'something', 'slowed', 'appreciation', 'voluntarily', 'walking', 'try', 'torn', 'booster', 'united', 'recursion', 'parentselectorappendchildexampleframe', 'working', 'nano', 'q1468', 'selfrealization', 'year', 'granulated', 'also', 'secured', 'individual', '86', 'upper', 'līquus', 'climate', 'finetuning', 'airtek', 'fortress', 'feel', 'fineliner', 'cute', 'totally', 'agatha', 'windblown', 'oliveremailcom', 'unit', 'unfolds', 'tomorrow', 'asking', 'constituency', 'wording', 'recycles', 'suddenly', 'tripod', '619285437', 'rose', 'snowfall', 'handson', 'roof', 'braver', 'technical', 'corrosive', 'soy', 'body', 'background', 'ordered', 'al', 'flameless', 'video', 'create', 'straighten', 'reduces', 'thirst', 'dress', 'architect', 'v', 'stroll', 'pollution', 'embarks', 'apart', 'player', 'viewed', 'oasis', 'greater', 'gencives', 'republic', 'cherry', 'alley', 'gender', 'instead', 'justice', 'conflicting', 'beside', 'job', 'stopping', 'preparation', 'sea', 'amazon', 'varied', 'desired', 'bug', 'godfather', 'write', 'compostable', 'sale', 'youll', 'replaced', 'impressed', 'school', 'horizontal', 'csvfile', 'construct', 'horror', 'addictive', 'handmixing', 'counterpoint', 'preheat', 'ainsi', 'distracted', 'promptly', 'graceful', 'apology', 'airfare', 'nightlife', 'excessive', 'pole', 'articulate', 'fading', 'assess', 'scream', 'bus', 'relax', 'answer', 'listen', 'million', 'httpswwwoverleafcomlatextemplatesgijsshomeworktemplatexrhhfgqcfbft', 'cream', 'fund', 'diagnostic', 'brew', 'location', 'instant', 'colt', 'explore', 'symbol', 'tuna', 'gradschoolvidz', 'tab', 'curb', 'printanswer', '58', 'perfect', 'mount', 'sectionunnumbered', 'shelter', 'raise', 'assistant', 'january', 'baserunner', 'starred', '766', '33', 'addition', 'collected', 'minor', 'serve', 'collective', 'state', 'director', 'peak', 'henna', 'theyll', 'memory', 'swaying', 'equation', 'fuel', 'advantage', 'resolve', 'industryleading', 'tom', 'httpsstackoverflowcomquestions16994212removeanitemfromarrayusingunderscorejs', 'mainly', '13', 'rugged', 'simply', 'tucked', 'budgie', 'db7093', 'included', 'sealed', 'tile', 'lead', 'ratified', 'x1', '117', 'reach', 'parklike', 'concept', 'imagine', 'duplicate', 'economics', 'day', 'wearing', 'yellow', 'hugo', 'completely', 'a3', 'graphic', 'collaborator', 'delete', 'month', 'museum', 'commute', 'overlap', 'brit', 'web', 'north', 'testdriven', 'prayer', 'vacation', 'subtotal', 'prohibition', 'kind', 'strange', 'batter', 'mood', 'ill', 'deepest', 'spinach', 'laminate', 'deck', 'closed', 'larger', 'coming', 'focusing', 'eternal', 'tex', 'fault', 'contains', 'carved', 'owned', 'creation', 'nick', 'description', 'lining', 'pay', 'norway', 'incredible', 'government', 'rare', 'javascript', 'seated', 'right', 'juiced', 'pwd', 'yoga', 'dialog', 'helped', 'cardinal', 'iconic', 'silver', 'tuesday', 'least', 'kane', 'vowelsincludesstritolowercase', 'array', 'cough', 'vertebrate', 'spoke', 'accustomed', 'objectoriented', 'rock', 'guided', 'advice', 'arxiv', 'longerlasting', 'repeat', 'account', 'singing', 'endtoend', 'logn', 'suggestingremember', '190', 'sudoku', 'total', 'continue', 'micromolar', 'parallel', 'caused', 'hormone', 'safe', '43', 'word', 'none', 'aaron', 'pregnant', 'require', 'dimension', '52', 'subject', 'foundation', 'magnificent', 'suspended', 'open', 'oven', 'ferry', 'podcast', 'cave', 'watch', 'hopefully', 'don', 'ribbon', 'position', 'project', 'console', 'cook', 'george', 'foil', 'projected', 'recent', 'logging', 'discus', 'detail', 'explored', 'flavorful', 'everything', 'wind', 'lung', 'hiking', 'often', 'drill', 'consequently', 'courtyard', 'looking', 'cashier', 'rush', 'nitrous', 'receive', 'offered', 'son', '31', '9930', 'hell', 'track', 'debate', 'present', 'he', 'helpcentre', 'fish', 'declare', 'uno', 'unsalted', 'clothes', 'l', 'hollywood', 'integration', 'crowdsourcing', 'exclusion', 'intelligence', 'youve', 'l14', 'classic', 'reason', 'strength', '360', 'ac2', 'destiny', 'etc', 'highest', 'iot', 'false', '87557', 'buying', 'evening', 'breathtaking', 'applying', 'query', 'realizes', 'killer', 'hopkins', 'ion', 'singleplayer', 'quartered', 'excess', 'exhaustion', 'focus', 'wy', 'complex', 'piece', 'familythe', 'unfaltering', 'aftermath', '1788', 'several', 'rehearsingthe', 'calculated', 'wellmaintained', 'lush', 'commercial', 'souvent', 'steelers', 'member', '2704', 'sucked', 'content', 'dissolve', 'mistake', 'contact', 'compassion', 'rebecca', 'ideal', 'monitor', 'dog', '200', 'welloptimized', 'awakening', 'kiwi', 'unfortunately', 'origin', 'carolina', 'intro', 'private', 'warming', 'different', 'lacey', 'steam', 'oneofakind', 'drawing', 'plastic', 'lean', 'queen', 'alleyway', 'ups', 'forward', 'lowcarb', 'blade', 'tuck', 'represent', 'timeintensive', 'monterey', 'coconut', 'bob', 'popular', 'malady', 'said', 'ought', 'cpurdieemailcom', 'fiji', 'uncle', 'initiative', 'slot', 'lasagna', 'appears', 'noodle', 'axée', 'x435', 'foretelling', 'may', 'beating', 'weekend', 'young', 'orcid', 'hydrochloric', 'neuer', 'dent', 'atop', 'explicit', 'loop', 'valravn', 'winter', 'deal', 'prolonged', 'painted', '24', 'incorporate', 'diced', 'grip', '92', 'act', 'plank', 'spent', 'craniofacial', 'electronic', 'draw', 'skak', 'resetting', 'developed', 'unnecessary', 'improve', 'joke', 'updating', 'charged', '15', 'sugar100', 'multiple', 'decide', 'nab', 'convert', 'shirt', 'push', 'there', 'high', 'muqueuse', 'veggie', 'joint', 'picket', 'reasoning', 'techcrunch', 'budgetmidrangeluxury', 'chebbi', 'trend', '834671925', 'direction', 'pack', 'crew', 'syrup', 'study', '83', 'derby', 'melody', 'like', 'solve', 'thu', 'sugar', 'must', 'basic', 'performance', 'medication', 'ispowerofthreeint', 'universal', 'sensor', 'utility', 'celebrating', 'inciting', 'english', 'considered', 'defensive', 'innovation', 'theory', 'sahara', 'moore', 'strong', 'grand', 'decrease', 'paris', 'settled', 'utopia', 'pattern', 'cat', 'scalability', 'personal', 'statue', 'requires', 'armchair', 'production', 'adopting', 'montana', 'fortune', '114', 'wont', 'behalf', 'thought', 'circuit', 'batting', 'expert', 'empty', 'photosartwork', 'chessboard', '6149', 'edit', 'person1', 'sound', 'airbnb', 'palm', 'shop', 'developing', 'sharp', 'mental', 'adam', 'downward', 'anxiety', 'city', 'soda', 'pretrained', 'yearround', 'shrimp', 'coupon', 'ware', 'return', 'boutique', 'della', 'slanting', 'tidy', 'mccartney', 'appropriate', 'hears', 'hero', 'save', 'gluten', 'theoretical', 'development', 'kg', 'component', 'solid', 'satisfy', 'toughen', 'vinegar', 'businesscouplesfamilyfriendssolo', 'spain', 'course', 'mostly', 'httpsexamplecomthings', 'halloween', 'classical', 'usepackageblindtext', 'ruin', 'differently', 'thrown', 'mkqa', 'apply', 'stella', 'future', '591', 'announcing', 'inform', 'knee', 'favorite', 'becomes', '3', 'date', 'conclusion', 'issue', 'double', 'fantastic', 'writer', 'extractor', 'difficulty', 'played', 'shucked', 'daddy', 'dynamic', 'drawn', 'produce', 'optic', 'hurry', 'bunsen', 'hiring', 'base', 'carpe', 'sprinkle', 'end', 'greatest', 'coursewide', 'duck', 'oil', 'fold', 'pushup', 'sense', 'first', 'assuming', 'stellar', 'sou', 'fourth', 'want', 'property', 'dough', 'killing', '2746', '1850s', 'run', 'youd', 'ksar', 'team', 'labour', 'disappears', 'named', 'meaning', 'antique', 'laugh', 'attaching', 'hotcold', 'top', 'hostile', 'case', '600', 'winding', 'imagemaking', 'syntactic', 'airborne', 'traditional', 'squat', 'nonstick', 'pacific', 'quality', 'everyone', 'landing', 'marjorelle', 'certain', 'grassroots', 'knowledge', 'huh', 'overlooking', 'slow', 'clip', 'usually', '1100', 'mvc', 'discussed', 'desperation', 'manning', 'mind', 'difference', 'inflammation', 'grey', 'hellbound', 'competing', 'employer', 'refsheadpushnotifications', 'bos', '1941', 'mix', 'lex', 'k12', 'rodney', 'power', 'tor', 'made', 'twitter', 'eat', 'smooth', 'external', 'bandwidth', 'stupidity', 'college', 'attract', 'motivation', 'syllabus', 'consolelogaverage1', 'reply', 'la', 'see', 'robbins', 'floor', 'math', 'spice', 'regroup', 'soldier', 'spa', 'somewhere', 'would', 'researching', 'whisk', '62', 'spark', 'session', 'drama', 'bringing', 'plunge', 'visualize', 'hilarious', 'ground', 'movein', 'condo', 'package', 'parkmountains', 'submit', '2020', 'mahomes', 'extract', 'subway', 'accessibility', 'campground', 'focused', 'lively', 'uefa', 'cost', 'soft', 'server', 'promoting', 'format', 'tactic', 'output', 'methamphetamine', 'grower', 'facade', 'heading', '13th', 'droplet', 'gathering', 'law', 'recording', 'h1', 'married', 'fishing', 'lucia', 'develop', 'thing', 'dioxide', 'likely', 'fashionable', 'anglofrench', 'history', 'desk', '310', 'include', 'elizabeth', 'descriptive', 'spatula', 'constraint', 'capital', 'stressing', 'rabbit', 'arduino', 'thats', 'felt', 'alternative', 'pale', 'lava', 'headed', 'kolbyreese82emailcom', 'bird', 'foodbourne', 'seven', 'window', 'air', 'cae4e2', 'enlarge', 'talker', 'inspired', 'combine', 'convince', 'welcome', 'calcatta', 'control', 'data', 'procrastination', 'spearheading', 'jsonlist', 'ouarzazatemerzouga', 'step', 'game', '5050', 'escape', 'mishap', 'hǎo', 'approximately', 'love', 'sheet', 'removed', 'little', 'fna', 'dinner', 'checking', 'toxin', 'nongovernmental', 'exercise', 'algebra', 'dry', 'believe', 'dropped', 'simple', 'canada', 'awe', 'whenever', 'learning', 'ethical', 'devops', 'test', 'organism', 'waterfront', 'exampleframe', 'monitoring', 'garden', 'organizational', 'potter', 'press', '12v', 'wallpaper', 'obstruction', 'pm', 'lump', 'salt', 'blaring', 'maldives', 'intent', 'can', 'scoop', 'el', 'function', 'halfway', 'cashiering', 'hoary', 'drink', 'low', '2x', 'supposes', 'net', 'sold', 'omen', 'region', 'oliver', 'counter', 'good', 'jesse', 'recipe', 'bit', 'together', 'gazing', 'dickens', 'nuance', 'ray', 'sift', 'come', 'never', 'fall', 'sep', 'hat', 'whose', 'please', 'letter', 'flip', 'unites', 'acrylic', '150', 'weeding', 'guess', 'two', 'much', 'framework', 'ai', 'mischance', 'meet', 'rain', 'tbdtask', 'progress', 'people', 'message', '12th', 'restocked', 'countvowelsstr', 'random', 'drag', 'ab', 'explainable', 'per', 'stayed', 'antarctica', 'usa', 'unwavering', 'creative', 'wondered', 'kick', 'tapa', 'club', 'less', 'deserted', 'machine', 'compris', 'officer', 'class', 'allout', 'go', 'chamberlain', 'chopped', 'cinematography', 'surfer', 'action', 'monday', 'virgil', 'arrow', 'specifically', 'back', 'flexibility', '031', 'dissonance', 'increasing', 'swum', 'dades', '2000', 'sincerely', 'ask', 'sparkling', 'coastal', 'reese', 'apache', 'others', 'gasp', 'hop', 'health', 'cd', 'three', 'peyton', 'depart', 'valley', 'recession', 'confusion', 'view', 'lotion', 'saw', 'performing', 'enter', 'tip', 'programming', '642', 'ham', 'prismatic', 'napa', 'fix', 'allows', 'apis', 'command', 'met', 'httpsstackoverflowcomquestions40462369removeitemfromstoredarrayinangular2', 'friday', 'bustling', 'q4', 'kill', 'geology', 'resistant', 'week', 'german', 'communication', 'bakery', 'mixed', 'chunking', '6000', 'middle', 'available', 'explained', 'xyz', 'httpsopenspotifycomplaylist37i9dqzf1dxcekfjzjyzcc', 'real', 'overcome', 'corner', 'metallic', 'movie', 'null', '3gfgd', 'fridman', 'nation', 'become', 'chunk110', 'axés', 'twisting', 'goosebump', 'concern', 'map', 'contrived', '1776', 'faux', 'adventure', 'marathon', 'vertical', 'accordingly', 'mediterranean', 'g3g', 'participate', 'consonance', 'prevent', 'translate', 'consequence', 'local', 'fortified', 'opposed', 'category', 'synthesis', 'proposes', 'theyre', 'wife', 'unhappy', 'marrakech', 'popcorn', 'higher', 'february', 'charleston', 'sinister', 'darwin', '1500', 'a32', 'purchased', 'doesnt'}\n"
     ]
    }
   ],
   "source": [
    "# Combine all processed conversations into a single string\n",
    "all_processed_text = ' '.join(df['processed_messages'])\n",
    "\n",
    "# Split the combined text into individual words\n",
    "words = all_processed_text.split()\n",
    "\n",
    "# Use a set to find unique words\n",
    "unique_words = set(words)\n",
    "\n",
    "# Find the total number of unique words\n",
    "total_unique_words = len(unique_words)\n",
    "\n",
    "# Print the result\n",
    "print(f\"Total unique words: {total_unique_words}\")\n",
    "\n",
    "# Optionally, print the unique words\n",
    "print(unique_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# Fit the tokenizer on the 'processed_messages' column\n",
    "tokenizer.fit_on_texts(df['processed_messages'])\n",
    "\n",
    "# Convert the processed text into sequences of integers\n",
    "sequences = tokenizer.texts_to_sequences(df['processed_messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7321, 11)\n"
     ]
    }
   ],
   "source": [
    "# Define the sequence length (n-gram size)\n",
    "n_gram_length = 10  # You can adjust this for longer or shorter n-grams\n",
    "\n",
    "# Create n-gram sequences\n",
    "n_grams = []\n",
    "for seq in sequences:\n",
    "    for i in range(n_gram_length, len(seq)):\n",
    "        n_gram_sequence = seq[i-n_gram_length:i+1]\n",
    "        n_grams.append(n_gram_sequence)\n",
    "\n",
    "# Convert the list of n-grams to a numpy array\n",
    "n_grams = np.array(n_grams)\n",
    "\n",
    "# Get the total number of unique words\n",
    "total_unique_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Check the shape of the resulting n-grams\n",
    "print(n_grams.shape)  # This will give you (number of sequences, n+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = n_grams[:, :-1]\n",
    "y = n_grams[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the target variable (y)\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y = to_categorical(y, num_classes=total_unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7321, 10)\n",
      "(7321, 4216)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of X and y\n",
    "print(X.shape)  # Input shape\n",
    "print(y.shape)  # Output shape (one-hot encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 4215\n",
      "Shape of y: (7321, 4216)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Vocab size: {vocab_size}\")\n",
    "print(f\"Shape of y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.clip(X, 0, vocab_size - 1)  # Clip values to be within the valid range (0 to 4214)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "115/115 [==============================] - 25s 55ms/step - loss: 10.3797 - accuracy: 0.0027\n",
      "Epoch 2/50\n",
      "115/115 [==============================] - 6s 56ms/step - loss: 10.0766 - accuracy: 0.0027\n",
      "Epoch 3/50\n",
      "115/115 [==============================] - 6s 55ms/step - loss: 9.8715 - accuracy: 0.0063\n",
      "Epoch 4/50\n",
      "115/115 [==============================] - 7s 57ms/step - loss: 9.7093 - accuracy: 0.0092\n",
      "Epoch 5/50\n",
      "115/115 [==============================] - 6s 56ms/step - loss: 9.4829 - accuracy: 0.0164\n",
      "Epoch 6/50\n",
      "115/115 [==============================] - 7s 57ms/step - loss: 9.1204 - accuracy: 0.0294\n",
      "Epoch 7/50\n",
      "115/115 [==============================] - 6s 56ms/step - loss: 8.7893 - accuracy: 0.0620\n",
      "Epoch 8/50\n",
      "115/115 [==============================] - 7s 58ms/step - loss: 8.2566 - accuracy: 0.1124\n",
      "Epoch 9/50\n",
      "115/115 [==============================] - 7s 58ms/step - loss: 7.7635 - accuracy: 0.1824\n",
      "Epoch 10/50\n",
      "115/115 [==============================] - 6s 56ms/step - loss: 7.2056 - accuracy: 0.2576\n",
      "Epoch 11/50\n",
      "115/115 [==============================] - 7s 58ms/step - loss: 6.7609 - accuracy: 0.3393\n",
      "Epoch 12/50\n",
      "115/115 [==============================] - 7s 57ms/step - loss: 6.2790 - accuracy: 0.4172\n",
      "Epoch 13/50\n",
      "115/115 [==============================] - 7s 58ms/step - loss: 5.8416 - accuracy: 0.4941\n",
      "Epoch 14/50\n",
      "115/115 [==============================] - 7s 58ms/step - loss: 5.5486 - accuracy: 0.5453\n",
      "Epoch 15/50\n",
      "115/115 [==============================] - 7s 57ms/step - loss: 5.3545 - accuracy: 0.5883\n",
      "Epoch 16/50\n",
      "115/115 [==============================] - 7s 57ms/step - loss: 5.2637 - accuracy: 0.6174\n",
      "Epoch 17/50\n",
      "115/115 [==============================] - 7s 63ms/step - loss: 5.1006 - accuracy: 0.6406\n",
      "Epoch 18/50\n",
      "115/115 [==============================] - 8s 73ms/step - loss: 5.0441 - accuracy: 0.6551\n",
      "Epoch 19/50\n",
      "115/115 [==============================] - 7s 59ms/step - loss: 5.1838 - accuracy: 0.6547\n",
      "Epoch 20/50\n",
      "115/115 [==============================] - 8s 68ms/step - loss: 5.0198 - accuracy: 0.6681\n",
      "Epoch 21/50\n",
      "115/115 [==============================] - 7s 58ms/step - loss: 4.8990 - accuracy: 0.6800\n",
      "Epoch 22/50\n",
      "115/115 [==============================] - 9s 75ms/step - loss: 4.9487 - accuracy: 0.6744\n",
      "Epoch 23/50\n",
      "115/115 [==============================] - 7s 62ms/step - loss: 4.9755 - accuracy: 0.6759\n",
      "Epoch 24/50\n",
      "115/115 [==============================] - 6s 56ms/step - loss: 4.8632 - accuracy: 0.6849\n",
      "Epoch 25/50\n",
      "115/115 [==============================] - 7s 58ms/step - loss: 4.8163 - accuracy: 0.6901\n",
      "Epoch 26/50\n",
      "115/115 [==============================] - 6s 56ms/step - loss: 4.9594 - accuracy: 0.6772\n",
      "Epoch 27/50\n",
      "115/115 [==============================] - 7s 59ms/step - loss: 5.0260 - accuracy: 0.6744\n",
      "Epoch 28/50\n",
      "115/115 [==============================] - 7s 58ms/step - loss: 4.8723 - accuracy: 0.6823\n",
      "Epoch 29/50\n",
      "115/115 [==============================] - 7s 57ms/step - loss: 4.8225 - accuracy: 0.6838\n",
      "Epoch 30/50\n",
      "115/115 [==============================] - 7s 58ms/step - loss: 5.1184 - accuracy: 0.6681\n",
      "Epoch 31/50\n",
      "115/115 [==============================] - 6s 56ms/step - loss: 4.8991 - accuracy: 0.6815\n",
      "Epoch 32/50\n",
      "115/115 [==============================] - 7s 58ms/step - loss: 4.9599 - accuracy: 0.6774\n",
      "Epoch 33/50\n",
      "115/115 [==============================] - 7s 58ms/step - loss: 4.9949 - accuracy: 0.6737\n",
      "Epoch 34/50\n",
      "115/115 [==============================] - 7s 57ms/step - loss: 5.0025 - accuracy: 0.6658\n",
      "Epoch 35/50\n",
      "115/115 [==============================] - 7s 58ms/step - loss: 4.9945 - accuracy: 0.6633\n",
      "Epoch 36/50\n",
      "115/115 [==============================] - 7s 59ms/step - loss: 4.8658 - accuracy: 0.6708\n",
      "Epoch 37/50\n",
      "115/115 [==============================] - 7s 57ms/step - loss: 4.7597 - accuracy: 0.6839\n",
      "Epoch 38/50\n",
      "115/115 [==============================] - 7s 62ms/step - loss: 4.7394 - accuracy: 0.6853\n",
      "Epoch 39/50\n",
      "115/115 [==============================] - 7s 58ms/step - loss: 5.0135 - accuracy: 0.6696\n",
      "Epoch 40/50\n",
      "115/115 [==============================] - 7s 57ms/step - loss: 4.9806 - accuracy: 0.6789\n",
      "Epoch 41/50\n",
      "115/115 [==============================] - 7s 58ms/step - loss: 5.0908 - accuracy: 0.6644\n",
      "Epoch 42/50\n",
      "115/115 [==============================] - 7s 57ms/step - loss: 5.0815 - accuracy: 0.6622\n",
      "Epoch 43/50\n",
      "115/115 [==============================] - 7s 57ms/step - loss: 5.0486 - accuracy: 0.6712\n",
      "Epoch 44/50\n",
      "115/115 [==============================] - 7s 58ms/step - loss: 4.9474 - accuracy: 0.6778\n",
      "Epoch 45/50\n",
      "115/115 [==============================] - 7s 57ms/step - loss: 4.9290 - accuracy: 0.6805\n",
      "Epoch 46/50\n",
      "115/115 [==============================] - 7s 59ms/step - loss: 4.7310 - accuracy: 0.6939\n",
      "Epoch 47/50\n",
      "115/115 [==============================] - 7s 58ms/step - loss: 5.0274 - accuracy: 0.6759\n",
      "Epoch 48/50\n",
      "115/115 [==============================] - 7s 57ms/step - loss: 4.8145 - accuracy: 0.6864\n",
      "Epoch 49/50\n",
      "115/115 [==============================] - 7s 58ms/step - loss: 4.9294 - accuracy: 0.6763\n",
      "Epoch 50/50\n",
      "115/115 [==============================] - 7s 58ms/step - loss: 5.0014 - accuracy: 0.6726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2aca13e4f10>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure correct vocab size based on unique words\n",
    "vocab_size = 4215  # Number of unique words in the target\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 50, input_length=n_gram_length,))\n",
    "model.add(SimpleRNN(150, return_sequences=False))  \n",
    "model.add(Dropout(0.3)) \n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(4216, activation='softmax'))  # Final layer should have 4215 units, not 4216\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, y, batch_size=64, epochs=50, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "denote number aluminum aluminum hey chill river york city individual 6 exclusion\n"
     ]
    }
   ],
   "source": [
    "def generate_text(seed_text, next_words=10):\n",
    "    for _ in range(next_words):\n",
    "        # Tokenize the seed text\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        \n",
    "        # Pad the sequence to the required length\n",
    "        token_list = pad_sequences([token_list], maxlen=n_gram_length, padding='pre')\n",
    "        \n",
    "        # Predict the next word\n",
    "        predicted = np.argmax(model.predict(token_list, verbose=0), axis=-1)[0]\n",
    "        \n",
    "        # Get the predicted word from the token index\n",
    "        output_word = tokenizer.index_word.get(predicted)\n",
    "        \n",
    "        # If the predicted word is found in the index, add it to the seed text\n",
    "        if output_word:\n",
    "            seed_text += \" \" + output_word\n",
    "        else:\n",
    "            break  # Stop generating if no valid word is found\n",
    "    \n",
    "    return seed_text\n",
    "\n",
    "# Generate new text\n",
    "seed_text = \"denote number\"\n",
    "print(generate_text(seed_text, next_words=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(keras.layers.Embedding(input_dim=vocab_size, output_dim=100, input_length=n_gram_length))\n",
    "\n",
    "model2.add(keras.layers.Bidirectional(keras.layers.LSTM(100)))\n",
    "model2.add(keras.layers.Dense(100, activation='relu'))\n",
    "model2.add(keras.layers.Dense(4216, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "229/229 [==============================] - 15s 41ms/step - loss: 8.2028 - accuracy: 0.0034\n",
      "Epoch 2/10\n",
      "229/229 [==============================] - 9s 41ms/step - loss: 7.7360 - accuracy: 0.0044\n",
      "Epoch 3/10\n",
      "229/229 [==============================] - 9s 40ms/step - loss: 7.4568 - accuracy: 0.0063\n",
      "Epoch 4/10\n",
      "229/229 [==============================] - 9s 40ms/step - loss: 7.1029 - accuracy: 0.0108\n",
      "Epoch 5/10\n",
      "229/229 [==============================] - 9s 40ms/step - loss: 6.6729 - accuracy: 0.0182\n",
      "Epoch 6/10\n",
      "229/229 [==============================] - 9s 39ms/step - loss: 6.1533 - accuracy: 0.0318\n",
      "Epoch 7/10\n",
      "229/229 [==============================] - 9s 41ms/step - loss: 5.5657 - accuracy: 0.0520\n",
      "Epoch 8/10\n",
      "229/229 [==============================] - 9s 39ms/step - loss: 4.9453 - accuracy: 0.0854\n",
      "Epoch 9/10\n",
      "229/229 [==============================] - 9s 40ms/step - loss: 4.3030 - accuracy: 0.1382\n",
      "Epoch 10/10\n",
      "229/229 [==============================] - 9s 40ms/step - loss: 3.6506 - accuracy: 0.2079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2aca1dcfd00>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X, y, batch_size=32, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "denote number silicone interviewer fine fine fine fine fine fine add add\n"
     ]
    }
   ],
   "source": [
    "def generate_text(seed_text, next_words=10):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=n_gram_length, padding='pre')\n",
    "        predicted = np.argmax(model2.predict(token_list, verbose=0), axis=-1)[0]\n",
    "        output_word = tokenizer.index_word.get(predicted, '')\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text\n",
    "\n",
    "# Generate new text\n",
    "seed_text = \"denote number\"\n",
    "print(generate_text(seed_text, next_words=10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
